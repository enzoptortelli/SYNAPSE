---
tags:
  - "#theorem"
  - no-proof
link-tags:
  - "[[markov chain]]"
aliases:
  - esperança do número de visitas de uma cadeia de Markov a um estado
  - número de visitas de uma cadeia de Markov a um estado
---
# Theorem
Seja $N_i$ o número de vezes em que o estado $i$ é visitado pelo processo. Assim, $$P(N_i = k | X_0 = i) = f_i^{k-1}(1 - f_i) \qquad (1)$$. Logo,
$$N_i | (X_0 = i) \sim Geo(1-f_i)$$, onde $f_i$ é a [[202407150955|probabilidade de que a cadeia volte pro estado i]].

Repare que o expoente $k-1$, ao invés de $k$, se deve ao fato de que já é dado que a cadeia começa no estado $i$.

Dessa forma, $$E[N_i | X_0 = i] = \frac{1}{1-f_i}$$
# Proof


# Additional Comments
Note que essas definições são válidas para estado transientes, visto que, caso ele seja recorrente, $1- f_i = 0$, e $(1)$ não é uma distribuição de probabilidade.

Assim, se $E[N_i | X_0 = i] < \infty$, $i$ é transiente.

# Reference






