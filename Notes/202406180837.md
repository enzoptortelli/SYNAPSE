---
tags:
  - "#sketch"
  - unfinished
link-tags:
  - "[[design of experiments]]"
aliases:
  - trabalho final me623
---
# Ideas
Escolher o n√≠vel de signific√¢ncia do teste levando em conta que queremos um alto poder e temos apenas uma replica√ß√£o.

> How Much Replication is Necessary? A standard question that arises in almost every experiment is how much replication is necessary? We have discussed this in previous chapters, but there are some aspects of this topic that are particularly useful in 2k designs, which are used extensively for factor screening. That is, studying a group of k factors to determine which ones are active. Recall from our previous discussions that the choice of an appropriate sample size in a designed experiment depends on how large the effect of interest is, the power of the statistical test, and the choice of type I error. While the size of an important effect is obviously problem-dependent, in many practical situations experimenters are interested in detecting effects that are at least as large as twice the error standard deviation (2ùúé). Smaller effects are usually of less interest because changing the factor associated with such a small effect often results in a change in response that is very small relative to the background noise in the system. Adequate power is also problem-dependent, but in many practical situations achieving power of at least 0.80 or 80% should be the goal. We will illustrate how an appropriate choice of sample size can be determined using the 2 2 chemical process experiment. Suppose that we are interested in detecting effects of size 2ùúé. If the basic 2 2 design is replicated twice for a total of 8 runs, there will be 4 degrees of freedom for estimating a model-independent estimate of error (pure error). If the experimenter uses a significance level or Type I error rate of ùõº = 0.05, this design results in a power of 0.572 or 57.2%. This is too low, and the experimenter should consider more replication. There is another alternative that could be useful in screening experiments, use a higher type I error rate. In screening experiments Type I errors (thinking a factor is active when it really isn't) usually does not have the same impact than a Type II error (failing to identify an active factor). If a factor is mistakenly thought to be active, that error will be discovered in further work and so the consequences of this type I error is usually small. However, failing to identify an active factor is usually very problematic because that factor is set aside and typically never considered again. So in screening experiments experimenters are often willing to consider higher Type I error rates, say 0.10 or 0.20. Suppose that we use ùõº = 0.10 in our chemical process experiment. This would result in power of 75%. Using ùõº = 0.20 increases the power to 89%, a very reasonable value. The other alternative is to increase the sample size by using additional replicates. If we use three replicates there will be 8 degrees of freedom for pure error and if we want to detect effects of size 2ùúé with ùõº = 0.05, this design will result in power of 85.7%. This is a very good value for power, so the experimenters decided to use three replicates of the 22 design.

[[Montgomery, Design and Analysis of Experiments.pdf#page=251&selection=336,0,354,121|Montgomery, Design and Analysis of Experiments, page 251]]

# Reference
[[Design and Analysis of Experiments]]

