---
tags:
  - "#definition"
link-tags:
  - "[[markov chain]]"
aliases:
  - cadeias de Markov
---
# Definition 
Uma cadeia de Markov (CM) é um processo estocástico que satisfaz a propriedade markoviana; isto é, $$P(X_{n+1} = x_{n+1} | X_n = x_n, X_{n-1} = x_{n-1}, \dots, X_0 = x_0) = P(X_{n+1} = x_{x+1} | X_n = x_n) = P_{ij}$$
onde $x_{n+1}, x_n, \dots, x_0$ pertencem ao espaço de estados do processo.

# Additional Comments


# Reference




